{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOiWtHh95C9LrifQv9QWnwp"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["[![Run this Code In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/damieh1/ISCA_Instagram_Project/blob/main/parse_label_studio.ipynb)"],"metadata":{"id":"bJ8ywNWBDn3B"}},{"cell_type":"markdown","source":["\"\"\"\"\n","----------------------- --------------------------------------------\n","| Script generates a pd.df based the annotations from LabelStudio  |\n","--------------------------------------------------------------------\n","Parse a Label Studio JSON export (for image classification project) into a tidy pandas DataFrame.\n","\n","Works with the labeling config that includes the following controls:\n","- emotional_content (single choice)\n","- text_present (single choice)\n","- scene_types (multiple choice)\n","- support_for_terror (single choice)\n","- stance_target (multiple choice, optional)\n","- emotion_impact (rating, 1..7)\n","- dominant_emotion (single choice)\n","- transcribed_text (textarea)\n","- notes (textarea)\n","\n","USAGE\n","-----\n","1. Import you Data to Colab - Colab asks for direct file import\n","2. Run parsing functions\n","3. Generate dataframe\n","4. Backup CSV for the parse\n","5. Combine and match the parse with the raw data # no code written yet\n","-------\n","\"\"\""],"metadata":{"id":"qT02mHN999jw"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"qso5IDDP1N3E","executionInfo":{"status":"ok","timestamp":1755785386661,"user_tz":240,"elapsed":6214,"user":{"displayName":"Daniel Miehling","userId":"06062511450329140752"}},"outputId":"bcdf5f60-a170-459a-bb17-9d3261391562"},"source":["#Importing the data\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a834a8e8-9774-45bc-bec5-5102cfe5c838\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a834a8e8-9774-45bc-bec5-5102cfe5c838\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving project-43-at-2025-08-21-10-02-06ae6b7c.json to project-43-at-2025-08-21-10-02-06ae6b7c.json\n"]}]},{"cell_type":"code","source":["# Rename upload\n","json = uploaded"],"metadata":{"id":"3gSy-LjO9wZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run Parsing functions\n","from __future__ import annotations\n","import argparse\n","import json\n","from typing import Any, Dict, List, Optional, Tuple, Iterable\n","import pandas as pd\n","from pathlib import Path\n","\n","# Controls expected in config\n","SINGLE_CHOICE_FIELDS = {\"emotional_content\", \"text_present\", \"support_for_terror\", \"dominant_emotion\"}\n","MULTI_CHOICE_FIELDS  = {\"scene_types\", \"stance_target\"}\n","RATING_FIELDS        = {\"emotion_impact\"}\n","TEXTAREA_FIELDS      = {\"transcribed_text\", \"notes\"}\n","\n","ALL_FIELDS = list(SINGLE_CHOICE_FIELDS | MULTI_CHOICE_FIELDS | RATING_FIELDS | TEXTAREA_FIELDS)\n","\n","def _safe_get(d: dict, *keys, default=None):\n","    cur = d\n","    for k in keys:\n","        if not isinstance(cur, dict) or k not in cur:\n","            return default\n","        cur = cur[k]\n","    return cur\n","\n","def _result_to_values(res: dict) -> Tuple[str, Any]:\n","    field = res.get(\"from_name\")\n","    rtype = res.get(\"type\")\n","    value = res.get(\"value\", {})\n","\n","    if rtype == \"choices\":\n","        choices = value.get(\"choices\", [])\n","        return field, list(choices)  # keep list even for single-choice\n","    elif rtype == \"rating\":\n","        return field, value.get(\"rating\")\n","    elif rtype == \"textarea\":\n","        texts = value.get(\"text\", [])\n","        joined = \"\\n\".join([t for t in texts if isinstance(t, str)])\n","        return field, joined\n","    else:\n","        # Unknown/unsupported type — keep raw\n","        return field, value\n","\n","def _annotation_to_record(task: dict, ann: dict) -> dict:\n","        #Flatten a single annotation into a record.\n","    record = {\n","        \"task_id\": task.get(\"id\"),\n","        \"annotation_id\": ann.get(\"id\"),\n","        \"project\": task.get(\"project\"),\n","        \"image\": _safe_get(task, \"data\", \"image\"),\n","        \"annotator_id\": _safe_get(ann, \"completed_by\", \"id\") or ann.get(\"completed_by\"),\n","        \"annotator_username\": _safe_get(ann, \"completed_by\", \"email\") or _safe_get(ann, \"completed_by\", \"username\"),\n","        \"created_at\": ann.get(\"created_at\"),\n","        \"updated_at\": ann.get(\"updated_at\"),\n","        \"lead_time\": ann.get(\"lead_time\"),\n","        # Defaults for all expected fields\n","        **{f: None for f in ALL_FIELDS},\n","    }\n","\n","    results: List[dict] = ann.get(\"result\") or []\n","    # not yet tested\n","    if not results and \"results\" in ann:\n","        results = ann[\"results\"]\n","\n","    for res in results:\n","        field, val = _result_to_values(res)\n","        if not field:\n","            continue\n","\n","        if field in MULTI_CHOICE_FIELDS:\n","            # ensure list\n","            if isinstance(val, list):\n","                record[field] = val\n","            elif val is None:\n","                record[field] = []\n","            else:\n","                record[field] = [val]\n","        elif field in SINGLE_CHOICE_FIELDS:\n","            # pick first if list\n","            if isinstance(val, list):\n","                record[field] = val[0] if val else None\n","            else:\n","                record[field] = val\n","        elif field in RATING_FIELDS:\n","            record[field] = val\n","        elif field in TEXTAREA_FIELDS:\n","            record[field] = val\n","        else:\n","            # unknown control; store as-is\n","            record[field] = val\n","\n","    return record\n","\n","def _iter_records(tasks: Iterable[dict]) -> Iterable[dict]:\n","    for t in tasks:\n","        annotations = t.get(\"annotations\") or []\n","        # Some exports may use 'completions' (legacy)\n","        if not annotations and \"completions\" in t:\n","            annotations = t[\"completions\"]\n","        if not annotations:\n","            # produce an empty \"annotation\" record with task metadata only\n","            yield {\n","                \"task_id\": t.get(\"id\"),\n","                \"annotation_id\": None,\n","                \"project\": t.get(\"project\"),\n","                \"image\": _safe_get(t, \"data\", \"image\"),\n","                **{f: None for f in ALL_FIELDS},\n","            }\n","            continue\n","\n","        for ann in annotations:\n","            yield _annotation_to_record(t, ann)\n","\n","def _one_hot_multi(df: pd.DataFrame, fields: List[str]) -> pd.DataFrame:\n","    df = df.copy()\n","    for f in fields:\n","        # Gather unique values\n","        unique_vals = sorted({v for lst in df[f].dropna().tolist() for v in (lst if isinstance(lst, list) else [])})\n","        for u in unique_vals:\n","            col = f\"{f}__{u}\".replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"-\", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n","            df[col] = df[f].apply(lambda x: int(isinstance(x, list) and (u in x)))\n","    return df\n","\n","def _explode_multi(df: pd.DataFrame, fields: List[str]) -> pd.DataFrame:\n","    df = df.copy()\n","    for f in fields:\n","        df[f] = df[f].apply(lambda v: v if isinstance(v, list) and v else [None])\n","        df = df.explode(f, ignore_index=True)\n","    return df\n","\n","def parse_labelstudio_to_df(\n","    export_json_path: str | Path,\n","    explode_multi: bool = False,\n","    one_hot: bool = False\n",") -> pd.DataFrame: # Load a Label Studio JSON export and convert to a tidy DataFrame.\n","    p = Path(export_json_path)\n","    with p.open(\"r\", encoding=\"utf-8\") as f:\n","        data = json.load(f)\n","\n","    # Exports can be dict {\"tasks\": [...]} or list of tasks\n","    tasks = data.get(\"tasks\") if isinstance(data, dict) else data\n","    if tasks is None:\n","        raise ValueError(\"Could not find tasks in the export JSON. Expected a list or a dict with key 'tasks'.\")\n","\n","    records = list(_iter_records(tasks))\n","    df = pd.DataFrame.from_records(records)\n","\n","    # Normalize types\n","    if \"emotion_impact\" in df.columns:\n","        df[\"emotion_impact\"] = pd.to_numeric(df[\"emotion_impact\"], errors=\"coerce\")\n","\n","    # Ensure lists for multi fields (for empty annotations)\n","    for f in MULTI_CHOICE_FIELDS:\n","        if f in df.columns:\n","            df[f] = df[f].apply(lambda x: x if isinstance(x, list) else ([] if pd.isna(x) else [x]))\n","\n","    if explode_multi:\n","        df = _explode_multi(df, sorted(MULTI_CHOICE_FIELDS))\n","\n","    if one_hot:\n","        df = _one_hot_multi(df, sorted(MULTI_CHOICE_FIELDS))\n","\n","    return df"],"metadata":{"id":"OJcWq-Ts94p7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fbr-i63m2CUG"},"source":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"4f7ac674","executionInfo":{"status":"ok","timestamp":1755785857135,"user_tz":240,"elapsed":105,"user":{"displayName":"Daniel Miehling","userId":"06062511450329140752"}},"outputId":"efd7d7a5-c1b3-4cc8-9c9e-94de610ac8e1"},"source":["# Generate pd.df\n","file_name = list(uploaded.keys())[0]\n","df = parse_labelstudio_to_df(file_name)\n","display(df.head())"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["   task_id  annotation_id  project  \\\n","0    50745           4777       43   \n","1    50746           4778       43   \n","2    50747           4779       43   \n","3    50748           4780       43   \n","4    50749           4781       43   \n","\n","                                               image  annotator_id  \\\n","0  /data/upload/43/633a2ba7-00b293c5940bca885af4c...             1   \n","1  /data/upload/43/9e1f3a74-0ae9e0896a5284d0-C4CB...             1   \n","2               /data/upload/43/9c637d29-0-EB806.png             1   \n","3  /data/upload/43/30bfc2f9-0fa81a183df314c9443a1...             1   \n","4  /data/upload/43/7e06ea9a-1b7fae36776a21d746df2...             1   \n","\n","  annotator_username                   created_at  \\\n","0               None  2025-08-21T13:59:31.570615Z   \n","1               None  2025-08-21T14:00:47.965448Z   \n","2               None  2025-08-21T14:01:06.893513Z   \n","3               None  2025-08-21T14:01:20.738830Z   \n","4               None  2025-08-21T14:02:13.345014Z   \n","\n","                    updated_at  lead_time  \\\n","0  2025-08-21T13:59:31.570615Z     86.898   \n","1  2025-08-21T14:00:47.965448Z     54.783   \n","2  2025-08-21T14:01:06.893513Z     17.033   \n","3  2025-08-21T14:01:20.738830Z     12.425   \n","4  2025-08-21T14:02:13.345014Z     50.606   \n","\n","                                         scene_types  emotion_impact  \\\n","0                                 [Children present]             2.0   \n","1                               [Other / not listed]             3.0   \n","2                               [Other / not listed]             NaN   \n","3                                                 []             2.0   \n","4  [Interview / talk show / speaker portrait, Oth...             NaN   \n","\n","  transcribed_text  text_present           emotional_content  \\\n","0             None       No text  No (neutral/informational)   \n","1             None  Text visible     Yes (clearly emotional)   \n","2             None       No text  No (neutral/informational)   \n","3             None       No text                     Unclear   \n","4             None       No text  No (neutral/informational)   \n","\n","       dominant_emotion  stance_target support_for_terror notes  \n","0  Empathy / Compassion  [Other / N/A]                 No  None  \n","1                 Anger  [Anti-Israel]                 No  None  \n","2               Neutral  [Other / N/A]                 No  None  \n","3                  Fear  [Other / N/A]                 No  None  \n","4                 Other  [Other / N/A]                 No  None  "],"text/html":["\n","  <div id=\"df-4d3a085e-0316-48dc-8722-9f691a285b56\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>task_id</th>\n","      <th>annotation_id</th>\n","      <th>project</th>\n","      <th>image</th>\n","      <th>annotator_id</th>\n","      <th>annotator_username</th>\n","      <th>created_at</th>\n","      <th>updated_at</th>\n","      <th>lead_time</th>\n","      <th>scene_types</th>\n","      <th>emotion_impact</th>\n","      <th>transcribed_text</th>\n","      <th>text_present</th>\n","      <th>emotional_content</th>\n","      <th>dominant_emotion</th>\n","      <th>stance_target</th>\n","      <th>support_for_terror</th>\n","      <th>notes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50745</td>\n","      <td>4777</td>\n","      <td>43</td>\n","      <td>/data/upload/43/633a2ba7-00b293c5940bca885af4c...</td>\n","      <td>1</td>\n","      <td>None</td>\n","      <td>2025-08-21T13:59:31.570615Z</td>\n","      <td>2025-08-21T13:59:31.570615Z</td>\n","      <td>86.898</td>\n","      <td>[Children present]</td>\n","      <td>2.0</td>\n","      <td>None</td>\n","      <td>No text</td>\n","      <td>No (neutral/informational)</td>\n","      <td>Empathy / Compassion</td>\n","      <td>[Other / N/A]</td>\n","      <td>No</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50746</td>\n","      <td>4778</td>\n","      <td>43</td>\n","      <td>/data/upload/43/9e1f3a74-0ae9e0896a5284d0-C4CB...</td>\n","      <td>1</td>\n","      <td>None</td>\n","      <td>2025-08-21T14:00:47.965448Z</td>\n","      <td>2025-08-21T14:00:47.965448Z</td>\n","      <td>54.783</td>\n","      <td>[Other / not listed]</td>\n","      <td>3.0</td>\n","      <td>None</td>\n","      <td>Text visible</td>\n","      <td>Yes (clearly emotional)</td>\n","      <td>Anger</td>\n","      <td>[Anti-Israel]</td>\n","      <td>No</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>50747</td>\n","      <td>4779</td>\n","      <td>43</td>\n","      <td>/data/upload/43/9c637d29-0-EB806.png</td>\n","      <td>1</td>\n","      <td>None</td>\n","      <td>2025-08-21T14:01:06.893513Z</td>\n","      <td>2025-08-21T14:01:06.893513Z</td>\n","      <td>17.033</td>\n","      <td>[Other / not listed]</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","      <td>No text</td>\n","      <td>No (neutral/informational)</td>\n","      <td>Neutral</td>\n","      <td>[Other / N/A]</td>\n","      <td>No</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>50748</td>\n","      <td>4780</td>\n","      <td>43</td>\n","      <td>/data/upload/43/30bfc2f9-0fa81a183df314c9443a1...</td>\n","      <td>1</td>\n","      <td>None</td>\n","      <td>2025-08-21T14:01:20.738830Z</td>\n","      <td>2025-08-21T14:01:20.738830Z</td>\n","      <td>12.425</td>\n","      <td>[]</td>\n","      <td>2.0</td>\n","      <td>None</td>\n","      <td>No text</td>\n","      <td>Unclear</td>\n","      <td>Fear</td>\n","      <td>[Other / N/A]</td>\n","      <td>No</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50749</td>\n","      <td>4781</td>\n","      <td>43</td>\n","      <td>/data/upload/43/7e06ea9a-1b7fae36776a21d746df2...</td>\n","      <td>1</td>\n","      <td>None</td>\n","      <td>2025-08-21T14:02:13.345014Z</td>\n","      <td>2025-08-21T14:02:13.345014Z</td>\n","      <td>50.606</td>\n","      <td>[Interview / talk show / speaker portrait, Oth...</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","      <td>No text</td>\n","      <td>No (neutral/informational)</td>\n","      <td>Other</td>\n","      <td>[Other / N/A]</td>\n","      <td>No</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d3a085e-0316-48dc-8722-9f691a285b56')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4d3a085e-0316-48dc-8722-9f691a285b56 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4d3a085e-0316-48dc-8722-9f691a285b56');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-0dd89281-8e6b-4522-83f3-4d23cbf51d43\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0dd89281-8e6b-4522-83f3-4d23cbf51d43')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-0dd89281-8e6b-4522-83f3-4d23cbf51d43 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"Out of range float values are not JSON compliant: nan"}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0a59cf80","executionInfo":{"status":"ok","timestamp":1755786111056,"user_tz":240,"elapsed":16,"user":{"displayName":"Daniel Miehling","userId":"06062511450329140752"}},"outputId":"d53a8352-d9a9-4b15-ff3e-52531f426591"},"source":["# Generate backup CSV from annotation parse\n","df.to_csv('labelstudio_output.csv', index=False)\n","print(\"DataFrame saved to labelstudio_output.csv\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DataFrame saved to labelstudio_output.csv\n"]}]}]}
